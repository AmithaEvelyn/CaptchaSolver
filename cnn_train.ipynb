{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_size = 64  \n",
    "num_classes = 33  \n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "validation_split = 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(r\"D:\\Captcha\\yolo+cnn\\captcha_dataset_yolo\", transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_size = len(dataset)\n",
    "val_size = int(validation_split * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (input_size // 8) * (input_size // 8), 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 1.8607, Train Accuracy: 0.4848\n",
      "Val Loss: 0.1535, Val Accuracy: 0.9583\n",
      "Epoch 2/20\n",
      "Train Loss: 0.2857, Train Accuracy: 0.9218\n",
      "Val Loss: 0.0563, Val Accuracy: 0.9883\n",
      "Epoch 3/20\n",
      "Train Loss: 0.1556, Train Accuracy: 0.9559\n",
      "Val Loss: 0.0323, Val Accuracy: 0.9950\n",
      "Epoch 4/20\n",
      "Train Loss: 0.1019, Train Accuracy: 0.9717\n",
      "Val Loss: 0.0383, Val Accuracy: 0.9933\n",
      "Epoch 5/20\n",
      "Train Loss: 0.0994, Train Accuracy: 0.9705\n",
      "Val Loss: 0.0305, Val Accuracy: 0.9967\n",
      "Epoch 6/20\n",
      "Train Loss: 0.0792, Train Accuracy: 0.9767\n",
      "Val Loss: 0.0086, Val Accuracy: 0.9967\n",
      "Epoch 7/20\n",
      "Train Loss: 0.0692, Train Accuracy: 0.9817\n",
      "Val Loss: 0.0062, Val Accuracy: 0.9983\n",
      "Epoch 8/20\n",
      "Train Loss: 0.0513, Train Accuracy: 0.9809\n",
      "Val Loss: 0.0235, Val Accuracy: 0.9933\n",
      "Epoch 9/20\n",
      "Train Loss: 0.0370, Train Accuracy: 0.9892\n",
      "Val Loss: 0.0319, Val Accuracy: 0.9950\n",
      "Epoch 10/20\n",
      "Train Loss: 0.0442, Train Accuracy: 0.9834\n",
      "Val Loss: 0.0160, Val Accuracy: 0.9950\n",
      "Epoch 11/20\n",
      "Train Loss: 0.0449, Train Accuracy: 0.9867\n",
      "Val Loss: 0.0217, Val Accuracy: 0.9950\n",
      "Epoch 12/20\n",
      "Train Loss: 0.0426, Train Accuracy: 0.9867\n",
      "Val Loss: 0.0195, Val Accuracy: 0.9950\n",
      "Epoch 13/20\n",
      "Train Loss: 0.0570, Train Accuracy: 0.9846\n",
      "Val Loss: 0.0209, Val Accuracy: 0.9950\n",
      "Epoch 14/20\n",
      "Train Loss: 0.0559, Train Accuracy: 0.9850\n",
      "Val Loss: 0.0104, Val Accuracy: 0.9983\n",
      "Epoch 15/20\n",
      "Train Loss: 0.0346, Train Accuracy: 0.9892\n",
      "Val Loss: 0.0153, Val Accuracy: 0.9967\n",
      "Epoch 16/20\n",
      "Train Loss: 0.0341, Train Accuracy: 0.9888\n",
      "Val Loss: 0.0246, Val Accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "Train Loss: 0.0381, Train Accuracy: 0.9867\n",
      "Val Loss: 0.0127, Val Accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "Train Loss: 0.0421, Train Accuracy: 0.9859\n",
      "Val Loss: 0.0296, Val Accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "Train Loss: 0.0529, Train Accuracy: 0.9896\n",
      "Val Loss: 0.0322, Val Accuracy: 0.9950\n",
      "Epoch 20/20\n",
      "Train Loss: 0.0384, Train Accuracy: 0.9900\n",
      "Val Loss: 0.0134, Val Accuracy: 0.9967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accuracy = val_correct / len(val_loader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "torch.save(model.state_dict(), 'test_cnn.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
